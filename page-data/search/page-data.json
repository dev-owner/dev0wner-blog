{"componentChunkName":"component---src-pages-search-jsx","path":"/search/","result":{"data":{"allMarkdownRemark":{"nodes":[{"excerpt":"서문    이전 포스트에서 Apache Arrow에 대해 간략한 내용과 특징들을 살펴보았습니다. 이번에는 내부 구현을 보면서 조금 더 살펴보려고 합니다. 여러 언어 구현체가 있지만, 가장 익숙한 Python으로 보겠습니다. PyArrow Architecture     Python에서는 Apache Arrow를 PyArrow라는 이름으로 구현하였습니다. P…","fields":{"slug":"/2023-study-apache-arrow-3/"},"frontmatter":{"date":"February 06, 2023","title":"2023 부담있는 스터디 - Apache Arrow 코드 파헤치기","tags":["Apache Arrow"]},"rawMarkdownBody":"\n## 서문\n&nbsp;&nbsp; 이전 포스트에서 Apache Arrow에 대해 간략한 내용과 특징들을 살펴보았습니다. 이번에는 내부 구현을 보면서 조금 더 살펴보려고 합니다. 여러 언어 구현체가 있지만, 가장 익숙한 Python으로 보겠습니다.\n\n## PyArrow Architecture\n\n![PyArrow Architecture](pyararow.png)\n\n&nbsp;&nbsp; Python에서는 Apache Arrow를 PyArrow라는 이름으로 구현하였습니다. PyArrow는 Arrow C++ Implementation에서 제공하는 대부분의 기능을 `Cython`으로 wrapping 하여 제공한다고 보면 됩니다. \n\n## Quick Start\n\n```python\n...\nmmap_file = pa.memory_map('demo-file.arrow', r)\ntable = pa.ipc.RecordBatchFileReader(mmap_file).read_all()\ndf = table.to_pandas()\n# pandas -> arrow -> pandas\ntable_pa = pa.Table.from_pandas(df_pandas)\ndf_pandas = table_pa.to_pandas()\n...\n```\n\n&nbsp;&nbsp; 위 코드는 Apache Arrow Quick Start code 입니다. \n"},{"excerpt":"서문    이전 포스트에서 Apache Arrow에 대해 간략한 내용과 특징들을 살펴보았습니다. 이번에는 이어서 성능이점 중 네트워크 관련하여 어떤 이점을 가지고 있는지 좀 더 살펴보겠습니다. Arrow Flight RPC    Apache Arrow에서 가져가는 성능상의 이점 중  항목이 있습니다. 이 부분을 알아보기 위해 Arrow Flight RPC…","fields":{"slug":"/2023-study-apache-arrow-2/"},"frontmatter":{"date":"February 05, 2023","title":"2023 부담있는 스터디 - Apache Arrow Flight RPC","tags":["Apache Arrow Flight"]},"rawMarkdownBody":"\n## 서문\n&nbsp;&nbsp; 이전 포스트에서 Apache Arrow에 대해 간략한 내용과 특징들을 살펴보았습니다. 이번에는 이어서 성능이점 중 네트워크 관련하여 어떤 이점을 가지고 있는지 좀 더 살펴보겠습니다.\n\n## Arrow Flight RPC\n\n&nbsp;&nbsp; Apache Arrow에서 가져가는 성능상의 이점 중 `Remove Network Overhead` 항목이 있습니다. 이 부분을 알아보기 위해 Arrow Flight RPC가 무엇인지 알아 보았습니다. Arrow Flight RPC는 분산시스템에서 데이터를 서버간 전송하는 것에 사용하도록 디자인 된 고성능 RPC(Remote Procedure Call) Framework 입니다. gRPC와 IPC Format을 기반으로 구축이 되었다고 하는데, 본격적으로 알아보기 전에 RPC는 무엇인지 짚고 넘어가 보겠습니다. \n\n### RPC\n\n&nbsp;&nbsp; RPC는 한국어로 원격 프로시저 호출로써 별도의 원격제어를 위한 코딩 작업 없이 다른 주소공간에서 함수나 프로시저를 실행할 수 있게 하는 프로세스간 통신 기술을 말합니다. 즉, 원격지의 프로세스에 접근하여 프로시저 또는 함수를 호출하는 건데요, IPC(Inter Process Communication)의 한 종류입니다. RPC를 이용하면 프로그래머는 함수가 있는 위치에 상관 없이 동일하게 함수를 호출 가능합니다. \n![RPC-model](./RPC-model.png)\n&nbsp;&nbsp; RPC의 목적은 크게 2가지입니다.\n\n1. Encapsulation - Client-Server 간 커뮤니케이션 상세 정보 감추기\n2. Interface - Client, Server는 일반 메소드를 호출하는 것 처럼 행동\n\n![RPC-mechanism](./RPC-mechanism.png)\n\n&nbsp;&nbsp; 위 그림을 잘 보면, Stub과 RPC Runtime이 Client, Server에 각각 존재하여 Pack/Unpack, Receive/Send 동작을 하는 것을 볼 수 있습니다. 이러한 매커니즘을 통해 RPC를 사용하면 원격지에 있어도 로컬에서 호출하는 것과 같은 효과를 볼 수가 있는것이죠. 이러한 RPC의 대표적인 구현체로는 ProtocolBuffer, Thrift 등이 있습니다.\n\n&nbsp;&nbsp; RPC의 장점으로는 로컬에서 호출하면서도 원격지를 신경쓸 필요가 없다는게 있습니다. 하부 네트워크는 프로토콜 매커니즘에 맡길 수가 있는 것이죠. 이에 프로세스간 통신 또한 쉽게 구현이 가능합니다. 단점으로는, 네트워크를 이용하기 때문에 호출 실행과 반환이 보장되지 않는다는점과 보안적인 측면에서 신경을 많이 써야 할 부분이 있다는 점 입니다.\n\n### gRPC\n\n&nbsp;&nbsp; gRPC는 구글에서 개발했고, 어느 환경에서나 실행할 수 있는 고성능 RPC 프레임워크입니다. 아래 아키텍처를 보면 위에서 설명한 RPC와 유사하다는 것을 알 수 있습니다. \n\n![gRPC](./gRPC.png)\n\n&nbsp;&nbsp; 여기 보면 stub이 계속 등장하는데요, stub이란 RPC의 핵심 개념으로 Parameter 객체를 Message로 Marshalling, Unmarshalling 하는 레이어입니다. \n\n> Marshalling, Unmarshalling vs Serialization, Deserialization?\n- Serialization: 객체의 주소값이 참조하는 값을 저장하고, Primitive한 데이터로 변환하여 byte stream으로 저장 후 다른곳에서 다시 풀 수 있도록 하는 것을 말합니다.\n- Marshalling: 변환하는 일련의 과정 자체를 뜻합니다. 즉 Marshalling Serialization 포함합니다.\n\n&nbsp;&nbsp; gRPC는 IDL(Interface Definition Language)로 protocol buffer를 사용합니다. protocol buffer란 JSON, XML과 비슷한 데이터 직렬화 구조 중 하나입니다. gRPC의 특징으로는 높은 생산성과 다양한 언어 플랫폼을 지원하여 확장성이 좋고, HTTP/2 기반 양방향 스트리밍을 지원하며 각종 부분에서 최적화를 진행하여 성능이 뛰어나다는 장점이 있습니다.\n\n\n"},{"excerpt":"2023-01-29 일요일   전날 AWS 자격증 시험을 저녁 9시부터 11시반까지 쳐서 그런지 아침에 일어나기가 너무 힘들었습니다. 배고프다고 하는 와이프와 실시간으로 꼬르륵 소리를 내는 강아지 소리를 들으며 간신히 일어나서 아침부터 김밥을 사왔죠. 그리고 전날 미처 못간 운동을 가면서 아침을 개운하게 시작했네요. 강남, 친구   오늘은 오랫만에 주말에…","fields":{"slug":"/2023-01-29/"},"frontmatter":{"date":"January 29, 2023","title":"2023-01-29 일상","tags":["Daily","chatgpt","이루다"]},"rawMarkdownBody":"\n## 2023-01-29 일요일\n\n  전날 [AWS 자격증](https://www.credly.com/badges/3c560133-1c3b-4dbc-96b8-4edc5f7f713f/public_url) 시험을 저녁 9시부터 11시반까지 쳐서 그런지 아침에 일어나기가 너무 힘들었습니다. 배고프다고 하는 와이프와 실시간으로 꼬르륵 소리를 내는 강아지 소리를 들으며 간신히 일어나서 아침부터 김밥을 사왔죠. 그리고 전날 미처 못간 운동을 가면서 아침을 개운하게 시작했네요.\n\n## 강남, 친구\n  오늘은 오랫만에 주말에 친구들을 보는 날 입니다. 친한 대학교 친구들과 오랜만에 만났죠. 와이프 추천으로 강남역 [진해장](https://naver.me/xiv5mYor) \n  이라는 곳에 갔는데, 조금 비싸긴 했지만 엄청 맛있었습니다. 오랜만에 만나 이런저런 이야기를 하다가, 꽤 재미있는 주제로 이야기를 했었죠.\n\n### ChatGPT, 이루다, AI\n  노기마기라는 별명을 가진 친구가 있는데, 갑자기 [이루다](https://luda.ai/)와 [ChatGPT](https://openai.com/blog/chatgpt/) 이야기를 하며 재밌는 이야기를 시작합니다. 2023년 현재, 사람과 대화가 꽤 의미있는 수준으로 가능할 만큼 AI들의 수준이 많이 올라왔고 이를 곰곰히 생각해본 친구가 가상 BJ를 만들어서 24시간 돌려보겠다는 생각을 한거죠. 이쪽 분야를 평소에 잘 모르는 사람에게는 이게 무슨 이상한 소리인가 싶겠지만, 저는 평소에도 ChatGPT를 업무에 잘 활용하고 있었기 때문에 꽤 재미있게 들렸습니다. 능력있는 친구라 이친구가 삘받으면 뭐라도 하겠구나 생각도 들었구요.\n\n### 어렵지만 가치가 많은 일 vs 쉽지만 가치가 적은 일\n  이 주제는 대부분의 사람들이 인생에 있어서 한번쯤 생각해볼 만한 주제인 것 같습니다. 이 역시 노기마기라는 친구가 최근에 하고 있는 고민인데 부서 이동을 고민하면서 나온 이야기입니다. A 부서는 핵심부서로, 일이 상상 이상으로 어렵고 시간을 많이 투자해야 하지만 젊을 때 고생을 그만큼 하면 나중에 혹시 좀 더 좋은 기회가 올 수도 있는 반면에 B 부서는 지원부서로, 일이 쉽고 워라밸이 좋은 반면에 시간이 지났을 때 자신의 가치가 떨어질 수도 있는 곳인데 이러한 상황 속에서 두 부서에 대한 고민이었습니다. 결론은 - B부서에 있으면서 자신의 가치를 올릴 수 있는 다른 방법을 찾아라! 는 느낌으로 되었지만, 저는 작년에 했던 이직이 A부서와 같은 느낌이었기 때문에(구체적으로 들어가면 약간 다르긴 하지만) 사실 이 선택은 확실히 개개인의 특성에 따라 다른 것 같다고 느꼈습니다.\n\n### 부동산\n  2023년 현재, 전 세계적으로 경제 상황이 좋지 않고 대한민국 역시 비슷하게 흘러가고 있습니다. 부동산 역시 비슷한데, 작년만 하더라도 끝도 모르고 치솟던 집값이 벌써 어마어마하게 떨어지면서 미달난 무순위 청약을 지원 하는지 마는지에 대한 이야기를 했습니다. 이는 부동산을 투자의 개념으로 보는지, 실거주의 개념으로 보는지에 따라 선택의 여지가 달라지게 되는데 이야기를 꺼낸 친구는 실거주를 생각하고 있고 평소에 투자에 감각이 많이 있던 친구도 아니라 부동산에 돈 묶이는 것에 개의치 않는다면 지금도 나쁘지 않다고 이야기를 했네요. 미래는 모르는 거니까 이런 이야기는 아주 조심스럽습니다.. :)\n\n## 집\n  친구들과 만나고 집에 왔더니 와이프와 복이가 기다리고 있네요. 가정을 꾸린지 1년 조금 넘었지만, 이런게 행복인가 싶습니다 :) 우리 복이 사진 보고 가세요! ㅎㅎ (사진이 약간 찌그러지는데, 클릭하면 잘 나오네요)\n\n  ![bokki](./2023-01-29-1.jpeg)\n\n"},{"excerpt":"서문   2023년을 맞아 기분전환도 하고 새로운 경험을 해보고 싶어, 이전 직장 동료(A씨)와 스터디를 시작했습니다. 마침 A씨도 새로운 것에 대한 갈증이 있었는지 금방 의기투합하여 날짜를 정하고 나름 빠르게 진행하게 되었는데요. 주제를 무엇을 할지 고민하다가 서로 Data Engineering 백그라운드를 가지고 있다보니 자연스럽게 그쪽으로 시선이 쏠…","fields":{"slug":"/2023-study-apache-arrow-1/"},"frontmatter":{"date":"January 29, 2023","title":"2023 부담있는 스터디 - Apache Arrow란 무엇인가?","tags":["Apache Arrow"]},"rawMarkdownBody":"\n## 서문\n&nbsp;&nbsp;2023년을 맞아 기분전환도 하고 새로운 경험을 해보고 싶어, 이전 직장 동료(A씨)와 스터디를 시작했습니다. 마침 A씨도 새로운 것에 대한 갈증이 있었는지 금방 의기투합하여 날짜를 정하고 나름 빠르게 진행하게 되었는데요. 주제를 무엇을 할지 고민하다가 서로 Data Engineering 백그라운드를 가지고 있다보니 자연스럽게 그쪽으로 시선이 쏠렸습니다만.. 평소에 안하던걸 해보고 싶다는 생각끝에 Apache Arrow를 첫 주제로 선정하게 되었습니다.\n\n&nbsp;&nbsp;사실 저는 이름만 간간히 들어보고 정확히 무엇을 하는건지 모르고 있었는데 spark, pandas 등 많은 라이브러리에서 사용하는 것을 보니 이쪽의 core라는 생각이 들었고 한번 보면 재밌겠다는 생각으로 시작을 하게 되었습니다. \n  \n## 스터디 계획\n&nbsp;&nbsp;가볍게 시작했지만 최대한 의미있는 스터디를 진행하기 위해 아래와 같은 규칙을 정하고 시작하였습니다.\n  - 하나의 주제에 대해 최대 6주 진행\n  - 주제가 끝날 떄 format은 상관없이 output을 만들기 (Blog, 발표, etc.)\n  - 인원이 2명이므로 벌칙 rule은 따로 없지만 최대한 책임감 있게 스터디 진행\n  - 이전 회차에 다음 회차 주제를 대략적으로 선정하고 각자 내용 파악해온 것을 공유. (서로 보는 관점이 다르기 떄문에 겹쳐도 상관없는 것으로 간주)\n\n## Apache Arrow란 도대체 무엇을 하는 녀석일까?\n![Apache Arrow definition](./apache-arrow-logo.png)\n\n&nbsp;&nbsp;공식 사이트에서 Apache Arrow 정의를 보면 다음과 같습니다. `A cross-language development platform for in-memory analytics` 처음 이걸 보고 든 생각은 \"아, 언어별로 제약 없이 in-memory 분석을 할 수 있게 도와주는 개발 플랫폼인가?\" 라는 아주 직관적인 생각을 했습니다. \n\n&nbsp;&nbsp;사실 처음에는 어떻게 언어간 제약없이 그게 가능할지부터 시작해서 많은 의문점들이 떠올랐지만 추후에 공부를 하고 보니 결국 저 소개 문장이 Apache Arrow를 정의하는데 적절한 문장이라는 것을 깨달을 수 있었습니다. 결국 Arrow의 가장 중요한 핵심은 서로 다른 인프라에서 데이터를 공유할때 직렬화, 역직렬화로 발생하는 `오버헤드를 줄이고자 하는 것`에 있었고, 이를 `언어나 플랫폼 상관없이` 메모리상에서 컬럼 구조(columnar)로 데이터를 정의하여 빠르게 읽고 쓸수 있도록 하는것에 있었습니다. \n\n![Apache Arrow abstract structure](./arrow-abstract-structure.png)\n\n&nbsp;&nbsp;굳이 Arrow를 다시 정의해보자면, `테이블형 데이터셋을 표현하기 위해 표준화된 언어-비종속적인 인메모리 컬럼형식 명세` 라고 할 수 있을 것 같습니다. 위의 그림을 보면, 여러 언어 혹은 플랫폼에서 Arrow API를 이용하여 메모리에서 데이터를 접근하는 그림을 볼 수 있습니다. \n\n### Columnar Data Format이란? \n\n![Columnar Data Format Structure](./arrow-columnar-data-format.png)\n\n&nbsp;&nbsp; 잠깐 위에서 스쳐 지나가듯이 나온 Columnar Data Format에 대해 짚고 넘어가겠습니다. 일반적으로 위 그림에서 우측과 같이 Row 기반으로 데이터를 저장하는 형태가 많이 익숙하실 텐데요. 이를 좌측 그림처럼 컬럼별로 저장하는 방식을 Columnar Data Format이라고 지칭합니다. 이러한 포맷에는 ORC, Parquet등이 존재합니다. \n\n&nbsp;&nbsp; 이러한 방식을 이용하는데는 데이터 분석에 있어서 Row 기반 저장방식에 비해 많은 이점을 가져갈 수 있기 때문입니다. 보통 분석을 하면 모든 컬럼에 대해 작업하기 보다는 특정 컬럼 위주로 작업하는 경향이 많고, 집계나 여러 처리가 같은 컬럼이 연속적으로 붙어있을 때 많은 연산 이점을 가져갈 수 있습니다. 또한, 압축에 있어서도 비슷한 데이터가 연속적으로 있는 것이 더 유리한 면도 있습니다. 이러한 이점들 덕분에 대량의 데이터 분석 환경에서는 대부분 데이터 저장 포맷을 Columnar로 사용하는 것이 `de-facto`라고 할 수 있습니다.\n\n## Apache Arrow의 구체적인 특징은 뭘까?\n\n&nbsp;&nbsp; 위의 설명으로 Arrow를 cross-platform에서 분석이 필요한 상황에 용이하겠구나라고 대략 이해할 수 있습니다. 그렇다면 좀 더 구체적으로 어떤 특징을 가지고 있을까요?  \n\n### 1. Performance Benefits\n\n&nbsp;&nbsp; Apache Arrow를 이용하면 아래와 같은 성능 이점을 가져갈 수 있다고 합니다.\n\n- Parallelism\n- Pipelining\n- Focus on CPU Efficiency\n- Zero Copy Data Sharing\n- Remove Network Overhead\n\n&nbsp;&nbsp; 이점을 보면 몇몇 익숙한 것과 그렇지 않은것이 눈에 띕니다. `Focus on CPU Efficiency`가 무엇을 의미하는 걸까요? 조금 찾아보니 CPU의 L2 Cache Locality를 이용하는 것과, SIMD Instruction에 대한 이야기가 나옵니다. Cahce Locality는 직관적으로 이해가 가는데, SIMD Instruction은 뭘까요? \n\n#### SIMD Instruction\n\n&nbsp;&nbsp; Single Instruction Multiple Data의 약자로써, CPU 연산을 하는 방식 중 하나입니다. CPU Single Clock Cycle안에 여러개의 연산을 동시에 수행하는 기법입니다. Vector 연산이라고도 불린다고 하네요. 아래 그림을 보면 직관적으로 이해가 되실 겁니다. 여러 연산을 CPU에서 한번에 수행할 수 있으니 그만큼 빨라지는 개념이죠. 물론 이게 가능하기 위해서는 여러 제약조건들이 조금 있긴 하지만, 적용할 수 있다면 성능 향상을 기대할 수 있을 것 같습니다. 조금 더 자세한 내용은 [위키](https://en.wikipedia.org/wiki/Single_instruction,_multiple_data) 등 Dive deep하게 공유하는 사이트 등을 참고 부탁 드립니다. \n\n![SIMD](./SIMD.png)\n\n#### Zero Copy Data Sharing\n\n&nbsp;&nbsp; 이름만 보면 데이터 공유시에 Copy를 하지 않아 성능이 향상된다는 개념으로 보입니다. 내용을 살펴보니, Columnar In-memory format으로 zero-copy serialization을 수행하는 feature를 지칭합니다. 기존 Python같은 언어에서 객체를 다른 플랫폼으로 보내기 위해서는 Pickle등을 통해 Serialization, De-serialization 단계가 필요했습니다. 이런 연산 자체가 굉장한 오버헤드이기 떄문에, apache arrow에서는 이 단계를 없애서 오버헤드를 제거하고자 하였고 이것이 zero-copy 개념입니다.\n\n![Serialization & De-serialization](./serialization.png)\n\n&nbsp;&nbsp; 구체적으로 보면, 직렬화가 없기 때문에 애초에 직렬화된 데이터 자체를 가지고 작업합니다. 이는 네트워크 전송시에도 직렬화가 필요없기 때문에 데이터 전송 측면에서도 아주 효율적입니다. 직렬화를 하지 않는다면 읽는 쪽에서 어떻게 읽을 수 있지? 라는 생각이 들 수 있는데, 이러한 부분을 apache arrow에서 처리해준다고 생각하시면 되겠습니다. (정확히는 arrow에서 사용하는 메모리 라이브러리에서 처리합니다. 이는 바로 이어서 말씀드리겠습니다)\n\n#### Google FlatBuffers\n\n![FlatBuffers](./flatbuffers.png)\n\n&nbsp;&nbsp; Apache Arrow 보는데 자꾸 다른 개념들을 소개하고 있어서 당황하실수도 있겠습니다. 하지만 대게 오픈소스가 그렇듯, Apache Arrow 또한 그 자체로 혼자 만들어진것이 아니라, 다른 수많은 오픈소스를 사용하며 만들어졌기에 공부를 할수록 다른 라이브러리에 대해 알아갈 수 밖에 없을 것 같습니다.(살려주세요)\n\n&nbsp;&nbsp; Google에서 개발한 FlatBuffers 공식 사이트 첫줄을 보면 다음과 같이 소개되어 있습니다. `FlatBuffers is an efficient cross platform serialization library for C++, C#, C, Go, Java, Kotlin, JavaScript, Lobster, Lua, TypeScript, PHP, Python, Rust and Swift.` 즉, 직렬화 라이브러리인데 여러 언어에서 사용할 수 있는 효율적인 크로스 플랫폼 라이브러리입니다. Google의 Protobuf와 유사하지만, Object 접근 전에 역직렬화를 안해도 되어 protobuf 보다 성능이 뛰어나다고 합니다. (하지만 반대급부로 코드 생성량이 더 많습니다)\n\n## Apache Arrow 1편 정리\n&nbsp;&nbsp; 지금까지 Apache Arrow가 무엇인지, 어떠한 이점을 가지고 있는지 살펴 보았는데, 내용이 길어져서 다음편에서도 성능 이점 관련하여 내용을 작성해 보겠습니다."},{"excerpt":"문제 AWS MWAA 에 custom xcom backend를 등록하기 위해  적용 시\n클러스터 업데이트 실패 해결 1. airflow.cfg 옵션 변경 실패에 대한 디버깅 이슈 재현 local에 mwaa 환경 구축 후  적용시 클러스터 상태 확인   확인 MWAA에서는 Config 실패로 인한 retry 등으로 API Timeout이 날 때 까지 오랜 …","fields":{"slug":"/mwaa-xcom-backend-config-issue/"},"frontmatter":{"date":"November 25, 2022","title":"AWS MWAA xcom backend configuration 이슈 해결","tags":["AWS","MWAA","Airflow"]},"rawMarkdownBody":"\n## 문제\n\n- AWS MWAA `airflow.cfg`에 custom xcom backend를 등록하기 위해 `core.xcom_backend:include.s3_xcom_backend.S3XComBackend` 적용 시\n  클러스터 업데이트 실패\n\n## 해결\n\n### 1. airflow.cfg 옵션 변경 실패에 대한 디버깅\n\n1. 이슈 재현\n    - local에 mwaa 환경 구축 후 `core.xcom_backend:include.s3_xcom_backend.S3XComBackend` 적용시 클러스터 상태 확인\n\n      ![](./2022-11-25-1.png)\n\n    - `AirflowConfigException: The object could not be loaded` 확인\n    - MWAA에서는 Config 실패로 인한 retry 등으로 API Timeout이 날 때 까지 오랜 시간 Cluster 상태가 `Updating`일 수 있습니다.\n\n2. 기본 값 적용시 내용 확인\n    - `\"core.xcom_backend\": \"airflow.models.xcom.BaseXCom\"`\n\n      → 성공\n\n      → Value값에 참조할 수 없는 값이 들어가면 실패하는 것을 유추할 수 있습니다\n\n3. `dags/` 폴더에 `s3_xcom_backend.py` 파일 생성 후 configuration 적용\n    - `\"core.xcom_backend\": \"s3_xcom_backend.S3XComBackend\"`\n\n   ![](./2022-11-25-2.png)\n\n   → **성공**\n\n### 2. MWAA Managed Node 접근 방법이 있을까?\n\n- Managed service이고 내부적으로 `Amazon ECS on Fargate`로 동작하기 때문에 airflow가 설치된 host의 shell로 접근할 수 있는 방법은 현재 존재하지 않습니다.\n- MWAA Architecture\n\n  ![](./2022-11-25-3.png)\n\n### 3. Airflow Configuration 변경 방법\n\n- 현재 MWAA에서는 airflow.cfg를 **직접적**으로 변경할 수 있는 방법을 제공하지 않습니다.\n- 가능한 방법은 아래 3가지 입니다.\n    1. `CFN`이나 `CDK`등 `IaC`를 사용하여 생성하거나 업데이트 할 때 옵션 반영\n        - `AirflowConfigurationOptions`\n    2. WEB UI를 통한 방법\n\n  ![](./2022-11-25-4.png)\n\n    3. AWS-CLI를 통한 방법\n\n    ```bash\n    #!/bin/bash\n    # update configuration\n    aws mwaa update-environment \\\n    --name xcom_backend_test \\\n    --airflow-configuration-options \"\"\"{\n      \\\"scheduler.dag_dir_list_interval\\\": \\\"5\\\",\n      \\\"scheduler.min_file_process_interval\\\": \\\"5\\\",\n      \\\"webserver.expose_config\\\": \\\"True\\\"\n      }\"\"\"\n      ```\n\n    ```bash\n    #!/bin/bash\n    # check configuration\n    aws mwaa get-environment \\\n    --name xcom_backend_test | \\\n    jq -r '.Environment.AirflowConfigurationOptions'\n    ```\n\n### 4. AWS-MWAA-LOCAL-RUNNER\n\n- MWAA 환경에 직접적인 접근은 어렵지만, [aws-mwaa-local-runner](https://github.com/aws/aws-mwaa-local-runner)를 통해 local에 MWAA를\n  mocking하여 테스트를 할 수 있습니다.\n\n  ```bash\n  1. /aws-mwaa-local-runner/docker/config/airflow.cfg 변경\n  2. ./mwaa-local-env build-image\n  3. ./mwaa-local-env start\n  4. airflow.cfg 반영 확인\n  ```\n\n### 5. 현재 MWAA에 적용된 airflow.cfg 값 및 환경변수 확인 방법\n\n- 여기에는 몇가지 방법이 있을 수 있습니다.\n\n1. 환경변수에서 확인\n\n  ```python\n  from __future__ import annotations\n\n  import logging\n  import os\n  from datetime import datetime, timedelta\n\n  from airflow import DAG\n  from airflow.operators.python import PythonOperator\n\n  logger = logging.getLogger(__name__)\n\n  with DAG(\n  'get_env_var',\n  default_args={\n    'depends_on_past': False,\n    'retries': 1,\n    'retry_delay': timedelta(minutes=5)\n    },\n    description='check mwaa configuration',\n    start_date=datetime(2022, 11, 26),\n    catchup=False\n    ) as dag:\n    def print_env_vars():\n    keys = dict(os.environ)\n    for k, v in keys.items():\n    print(f'{k}: {v}')\n\n  get_env_vars_operator = PythonOperator(\n  task_id='get_env_vars_task',\n  python_callable=print_env_vars\n  )\n  ```\n\n2. airflow.cfg 파일에서 확인\n\n  ```python\n  from __future__ import annotations\n\n  import logging\n  import os\n  from datetime import datetime, timedelta\n\n  from airflow import DAG\n  from airflow.operators.python import PythonOperator\n\n  logger = logging.getLogger(__name__)\n\n  with DAG(\n  'get_airflow_cfg_file',\n  default_args={\n    'depends_on_past': False,\n    'retries': 1,\n    'retry_delay': timedelta(minutes=5)\n    },\n    description='check mwaa configuration',\n    start_date=datetime(2022, 11, 26),\n    catchup=False\n    ) as dag:\n    def print_airflow_cfg():\n    with open(f\"{os.getenv('AIRFLOW_HOME')}/airflow.cfg\", 'r') as airflow_cfg:\n    file_contents = airflow_cfg.read()\n    print(f'\\n{file_contents}')\n\n  get_airflow_cfg_operator = PythonOperator(\n  task_id='get_airflow_cfg_task',\n  python_callable=print_airflow_cfg\n  )\n  ```\n\n3. airflow.configuration.conf 확인\n\n  ```python\n  from __future__ import annotations\n\n  import logging\n  from datetime import datetime, timedelta\n\n  from airflow import DAG\n  from airflow.configuration import conf\n  from airflow.operators.python import PythonOperator\n\n  logger = logging.getLogger(__name__)\n\n  with DAG(\n  'get_airflow_cfg',\n  default_args={\n    'depends_on_past': False,\n    'retries': 1,\n    'retry_delay': timedelta(minutes=5)\n    },\n    description='check mwaa configuration',\n    start_date=datetime(2022, 11, 26),\n    catchup=False\n    ) as dag:\n    def get_conf_vars():\n    logging.info(\n    f\"AIRFLOW__CORE__XCOM_BACKEND: {conf.get(section='CORE', key='XCOM_BACKEND')}\"\n    )\n\n  get_conf_vars_operator = PythonOperator(\n  task_id='get_conf_vars_task',\n  python_callable=get_conf_vars\n  )\n  ```\n\n4. MWAA Web UI에서 확인\n\n- 진행 과정 요약\n- \"webserver.expose_config\": \"True” 값을 먼저 설정합니다.\n\n![](./2022-11-25-5.png)\n\n- MWAA Web UI → Admin → Configuration에 들어갑니다.\n\n![](./2022-11-25-6.png)\n\n- UI에서 airflow.cfg를 확인합니다\n\n![](./2022-11-25-7.png)\n\n## Summary\n\n- MWAA의 세팅 관련 참고할만한 자료입니다.\n    - [https://catalog.workshops.aws/amazon-mwaa-for-analytics/en-US](https://catalog.workshops.aws/amazon-mwaa-for-analytics/en-US)\n    - [https://catalog.workshops.aws/aws-data-ingestion-pipeline/ko-KR](https://catalog.workshops.aws/aws-data-ingestion-pipeline/ko-KR)\n- xcom_backend의 값으로 **참조 가능한 경로에 파일이 있어야만** 클러스터 정상 업데이트 가능합니다.\n- airflow.cfg 값을 호스트에 접근하여 직접적으로 변경할 수 있는 방법은 없습니다.\n- MWAA는 Managed service이기 때문에, 위에 설명드린 방법으로 우회하여 구조 등을 확인하실 수 있습니다.\n- 현재 MWAA에서는 만약 `잘못된 세팅값`으로 클러스터를 업데이트 시키면, 내부 요인에 의해 장시간 클러스터pending 상태가 될 수 있습니다. 이를 대비하는 방법은 아래와 같습니다.\n    - aws-mwaa-local-runner로 미리 구성을 확인합니다.\n    - Network or Permission 문제일 수도 있기 때문에 [링크와](https://github.com/awslabs/aws-support-tools/tree/master/MWAA) 같은 도구를\n      이용하는 것을 추천 드립니다.\n    - MWAA `23년 마일스톤`으로 클러스터 업데이트 구성 지연 이슈는 해결될 예정입니다.\n\n## References\n\n- [https://programmaticponderings.com/2020/12/29/amazon-managed-workflows-for-apache-airflow-configuration-understanding-amazon-mwaas-configuration-options/](https://programmaticponderings.com/2020/12/29/amazon-managed-workflows-for-apache-airflow-configuration-understanding-amazon-mwaas-configuration-options/)\n- [https://airflow.apache.org/docs/apache-airflow/2.2.2/configurations-ref.html](https://airflow.apache.org/docs/apache-airflow/2.2.2/configurations-ref.html)\n- [https://docs.aws.amazon.com/mwaa/latest/userguide/configuring-env-variables.html#configuring-env-variables-airflow-ref](https://docs.aws.amazon.com/mwaa/latest/userguide/configuring-env-variables.html#configuring-env-variables-airflow-ref)\n- [https://docs.astronomer.io/learn/custom-xcom-backends](https://docs.astronomer.io/learn/custom-xcom-backends)\n- [https://docs.aws.amazon.com/mwaa/latest/userguide/what-is-mwaa.html](https://docs.aws.amazon.com/mwaa/latest/userguide/what-is-mwaa.html)"},{"excerpt":"Kafka on EKS, MSK Kafka는 이벤트 기반 아키텍처나 MSA 등등 현대 아키텍처 메세지 브로커로 빼놓을 수 없는 요소입니다. EKS 또한 대부분의 애플리케이션을 컨테이너로 배포하는 와중에 거의 필수적으로 사용하는 쿠버네티스를 보다 더 편리하게 사용할 때 많이 사용하는 요소입니다. 그러면 Kafka를 EKS에 올려서 사용하는 케이스에 대해 어…","fields":{"slug":"/aws-kafka-on-eks-vs-msk/"},"frontmatter":{"date":"November 20, 2022","title":"Kafka on EKS vs MSK","tags":["EKS","Kafka","MSK"]},"rawMarkdownBody":"\n## Kafka on EKS, MSK\n\nKafka는 이벤트 기반 아키텍처나 MSA 등등 현대 아키텍처 메세지 브로커로 빼놓을 수 없는 요소입니다.\n\nEKS 또한 대부분의 애플리케이션을 컨테이너로 배포하는 와중에 거의 필수적으로 사용하는 쿠버네티스를 보다 더 편리하게 사용할 때 많이 사용하는 요소입니다.\n\n그러면 Kafka를 EKS에 올려서 사용하는 케이스에 대해 어떤 방법이 있는지, 장단점이 무엇인지 알아봅시다.\n\n## 어떤 방법들이 있을까?\n\nEKS(K8S)에 카프카를 배포하는 방식에는 여러가지가 있을 것 같습니다.\n\n1. [Manage Kafka on Kubernetes: Strimzi](https://github.com/strimzi/strimzi-kafka-operator)\n2. [Banzai Cloud](https://github.com/banzaicloud/koperator)\n3. [Confluent](https://docs.confluent.io/operator/current/co-deploy-cfk.html)\n4. [Bitnami Kafka Helm chart](https://artifacthub.io/packages/helm/bitnami/kafka)\n\n위 방식들 말고도 여러 방법들이 있을 수 있습니다 :)\n\n## EKS on Kafka에서 생각해 볼 수 있는 점\n\n아무래도 직접 클러스터를 관리하다 보니 그 과정에서 배우는건 많을 것 같습니다. 그리고 모든것이 Admin의 통제 하에 관리되니 자유도나 디버깅 환경 또한 관리형 서비스보다는 편할 듯 싶습니다.\n\n그러나 그 이외 부분에서는 제 지식의 한계인지 더 좋은점은 생각하지 못했습니다. 대부분의 케이스에서 heavy lifting한 작업을 대신해주는 관리형 서비스가 낫다는 생각을 떨칠수가 없네요..\n\n구축하는 레퍼런스는 아래와 같은 사이트들이 있습니다.\n\n- https://medium.com/@JinnaBalu/kafka-cluster-on-amezon-eks-cluster-5850d67ae723\n- https://portworx.com/run-ha-kafka-amazon-elastic-container-service-kubernetes/\n\n\n## Amazon Managed Streaming for Apache Kafka(MSK)\n\nAWS에서는 Kafka를 managed service로 제공하는 MSK가 있습니다.\n\n위에서 잠깐 얘기했지만, 사실 대부분의 상황에서 MSK를 쓰는게 나을 것 같다는 생각입니다. 직접 설치 운영은 업데이트나 관리 측면에서 어려움을 겪을 확률이 크기 때문이고, Heavy lifting을 피할 수 있으면 피하는게 낫지 않을까라는 생각입니다.\n\n그리고 관리 측면을 제외하더라도, EKS와 달리 MSK는 **inter-az 데이터 전송 비용이 무료**이기 때문에 이러한 부분또한 고려해보면 좋습니다.\n\n\n## 결론\n\n아무래도 요즘 대부분의 케이스에서 직접 클러스터를 구축해서 사용하는 것 보다는 관리형 서비스를 사용하는게 여러가지 측면에서 효율성이 좋은 것 같습니다. 단, 회사의 규모가 너무 커서 On-premise에 직접 클러스터를 구축해서 관리해야 하는 상황이나 회사의 상황에 맞춰 특정 기능을 커스터마이징 해야 하는 상황 같은 경우 직접 해야 할 수도 있다고 생각합니다.\n\n"},{"excerpt":"실리콘밸리에서 날아온 데이터 엔지니어링 컨퍼런스 배경 제가 처음 실리콘밸리에서 날아온 데이터 엔지니어링 코스를 알게 된 건 아래 Youtube EO Channel에 올라온 한기용님 영상을 시청한 이후 입니다. 총 3부까지 있는 이 영상을 보고 나서 여러가지로 많은 생각을 하게 되었습니다. 혹시 아직 안보셨다면 한번쯤 가볍게 시청해보시는 것도 추천 드립니다…","fields":{"slug":"/programmers-data-engineering-conference/"},"frontmatter":{"date":"November 10, 2022","title":"2022 실리콘밸리에서 날아온 데이터 엔지니어링 컨퍼런스","tags":["Data Engineering","Programmers"]},"rawMarkdownBody":"\n## 실리콘밸리에서 날아온 데이터 엔지니어링 컨퍼런스\n\n### 배경\n\n제가 처음 [실리콘밸리에서 날아온 데이터 엔지니어링 코스](https://school.programmers.co.kr/learn/courses/14982)를 알게 된 건 아래 Youtube EO Channel에 올라온 한기용님 영상을 시청한 이후 입니다. 총 3부까지 있는 이 영상을 보고 나서 여러가지로 많은 생각을 하게 되었습니다. 혹시 아직 안보셨다면 한번쯤 가볍게 시청해보시는 것도 추천 드립니다.\n\n![](./2022-11-10-1.png)\n\n\n기존에 4년정도 데이터 엔지니어링 업무를 대기업에서 했었는데, 다른 곳에서는 어떻게 하고 있는지 궁금하기도 하고 내가 기존에 몰랐던 것들을 혹시 배울 수 있지 않을까 하여 코스를 신청하게 되었습니다. 듣고 보니 역시 기대를 저버리지 않고 강의가 나름 알차게 코스가 구성되어 있어 많은 걸 배울 수 있었던 것 같습니다. 역시 세상은 넓고 배울것은 많습니다 :)\n\n이 코스는 2022년 10월 기준 벌써 10기를 운영할 만큼 관련 종사자분들이 많이 듣고 계시기도 한데 이번에 코스 수강생들 대상으로 기용님이 데이터 엔지니어링 [컨퍼런스를](https://school.programmers.co.kr/learn/courses/15230) 열어주셔서 다녀온 후기를 작성해보려 합니다.\n\n\n![](./2022-11-10-2.png)\n(출처 : https://www.linkedin.com/in/hannahhejang/)\n\n\n### 목차\n\n금일 컨퍼런스 목차입니다.\n\n1. Airflow 환경 고도화하기 ([hoyeon lee](https://www.linkedin.com/in/ACoAAB0dV2QBZEoHPDMHVUaWR3F-okOKbAsuqhQ))\n2. 공공데이터 적재하기 ([Eunji Yi](https://www.linkedin.com/in/ACoAADdQHFoBvXqcwhKQG5YBRI0MNzRqGv_9j7w))\n3. 스타트업에서 데이터기반 의사결정 구조 만들기 ([Minjong Kim](https://www.linkedin.com/in/ACoAAAJgCuMBC6ob4tTNYE290unr86fVRLD7blM))\n4. 참석자 네트워킹\n\n\n비록 시간대가 퇴근 후 저녁시간대였지만 1번부터 3번까지 흥미로운 주제로 가득했고 이는 컨퍼런스에 참가할 충분한 동기부여가 되었습니다. 참석자간 네트워킹 시간 같은 경우, 제가 한번도 경험이 없기 때문에 사실 한국 특성상 서먹서먹하고 어색한 분위기가 흐르다가 끝나지 않을까 막연한 예상을 하고 일단 들어갔습니다.\n\n\n![](./2022-11-10-3.png)\n(출처 : https://www.linkedin.com/in/hannahhejang/)\n\n\n### Airflow 환경 고도화하기\n\n금일 컨퍼런스 첫번째 세션입니다. 쏘카의 [Grab](https://www.linkedin.com/in/ACoAAB0dV2QBZEoHPDMHVUaWR3F-okOKbAsuqhQ)님이 발표를 진행해 주셨습니다.\n\nGKE에서 K8S에 Airflow를 운영중이셨고, 통합 저장소로 BigQuery를 사용중이셨습니다. Airflow는 외부 저장소에서 BigQuery로 데이터를 적재할때 Batch 작업을 하기 위해 주로 사용했네요.\n\nAirflow 개발환경에 대한 이야기를 많이 말씀 해주셨습니다. 초기 아키텍처는 Git과 연계하여 DAG 버전관리와 동시에 Airflow에 배포되는 구조를 가져간 것 같구요. 운영환경 및 다른 동료들과 독립적인 환경을 구축하기 위해 Git Branch를 따로 가져가고 push되면 buddyworks, argocd를 통해 전용 airflow가 생성되어 테스트 및 검증 후 운영 merge되는 구조였다고 합니다.\n\n이런 구조에서 발생했던 자원 낭비, 불편한 환경, 긴 피드백 루프등의 많은 이슈로 인해 개발 환경 파이프라인을 docker compose 기반 로컬 노트북 환경으로 개선을 했다고 합니다. GCP Service Account를 통합 인증 수단으로 활용하였고, DAG Parsing Optimization을 위해 .airflowignore를 적극적으로 활용하셨다고 해요.\n\n이러한 개선 구조를 통해 클러스터를 띄우는 시간을 많이 단축시키고 피드백 루프를 단축시켜 생산성을 많이 향상시킬 수 있었다고 합니다.\n\n이어서 테스트 환경에 대한 이야기가 나왔는데, DAG 기본 문법 등을 체크하기 위해 pytest를 활용하셨고, pre commit hook을 사용하셨다고 합니다. Github Action에서 컨벤션, 테스트, 검증 등을 추가로 진행했다고 하네요.\n\n꿀팁들도 여러가지 소개해 주셨는데, 그 중에 CleanUp DAG를 만들어서 주기적으로 TI나 DagRun등의 정보를 삭제하여 전반적인 cluster 반응성 등을 향상시킨 점이 인상깊었습니다.\n\n모니터링, DAG 운영 알람, 보안 및 RBAC 적용, 외부 접속 정보에 대한 secret 저장소 활용, gcp secret manager 적용 등 많은 내용을 얘기해 주셨지만 시간이 많지는 않은 관계로 깊이는 다루지 못했던것 같습니다.\n\n이후 위 내용들을 포함한 전반적인 내용을 [SOCAR Tech Blog](https://tech.socarcorp.kr/data/2022/11/09/advanced-airflow-for-databiz.html)에서 소개해 주셔서 관심있으시면 한번 보시는걸 추천 드립니다.\n\n\n### 공공데이터 적재하기\n\n공공데이터 적재관련해서는 뱅크샐러드의 [Eunji Yi](https://www.linkedin.com/in/ACoAADdQHFoBvXqcwhKQG5YBRI0MNzRqGv_9j7w)님이 발표해주셨는데요, 처음 소개에서 NASA에서 일한 경력이 있으신게 아주 인상깊었습니다.\n\n이후에 뱅크샐러드에서 공공데이터 수집 관련해서 고군분투기를 말씀해 주셨는데, 본격적으로 공공데이터를 사용하기 위해 고려해야 할 것들이 얼마나 많은지 알 수 있었습니다.\n\n저는 이전에 한번 업무에서 공공데이터 수집을 해봤는데도 불구하고, 제대로 여러기관의 데이터를 사용하기 위해 필요한것들을 이번에 처음 알았는데요, 대표적으로 기억나는 어려운 점들은 아래와 같았습니다.\n\n\n    1. 정의가 같은 컬럼이라도, 발행하는 기관이나 API에 따라 이름이 다를 수 있다.\n    2. Enum으로 관리되어야 할 것 같은 상수값들이 역시 기관이나 API에 따라 이름이 다를 수 있다.\n    3. API명세가 아닌 2번과 같은 값 같은 경우는 내용이 언제 바뀔지 모른다.\n    4. 값이 기관에서만 알아볼 수 있는 특정 코드로 되어있는 경우가 대다수이다.\n    5. 4번과 같은 코드는 해당 API를 제공하는 곳이 아니라 저 멀리 이상한 다른 기관 사이트의 깊숙히 숨겨진 어딘가에 있다.\n    6. 공공기관에 문의는 한세월이다.\n\n\n뱅크샐러드에서는 위의 1번~6번을 해결하기 위해 중간 Layer를 두어 잘 추상화하여 사용하고 계신다고 하였습니다.\n\n사실 이런 부분이 실제 데이터를 본격적으로 사용하고자 할 때 크나큰 어려움을 겪는 부분이죠.\n이런 데이터 표준과 같은 내용은 이미 제공하는 측에서 관리하여 이용자가 편하게 이용할 수 있게끔 관리해야 한다고 생각합니다. (많은 기관에서 데이터를 open하고 있는것은 아주 긍정적이지만, 아직 갈길이 먼 것 같습니다)\n\n\n\n> 그닥 놀랍지 않게도 개인 개발자분이 중간 layer 비스무리한걸 [github](https://github.com/WooilJeong/PublicDataReader)에 올린걸 최근에 발견했습니다. 관심있으시면 한번 보시는걸 추천 드립니다. - 2022/11/21\n\n\n\n### 스타트업에서 데이터기반 의사결정 구조 만들기\n\n마지막 세션은 NOUL의 [Minjong Kim](https://www.linkedin.com/in/ACoAAAJgCuMBC6ob4tTNYE290unr86fVRLD7blM)님이 발표해주셨습니다.\n\n스타트업에서 어떤 문제를 발견하고, 해당 문제를 그냥 지나치지 않고 데이터를 기반으로 의사결정하여 개선해나가는 과정을 말씀해 주셨습니다.\n일을 하다 보니 데이터가 동료들이 작업하고 있는 환경의 데이터가 여기저기 파편화 되어 있고, 버전이 맞지 않으며 이로인해 비즈니스 임팩트까지 발생하는 것을 파악하셨고, 주 업무 분야가 아님에도 불구하고 이런것을 개선하기 위해 아래와 같은 과정을 진행하셨다고 합니다.\n\n\n    1. NAS, Google Spreadsheet 기반 파일 사용 추적 후 DB에 정규화하여 데이터 사용 및 정합성 측면 개선\n    2. ML 모델 평가 추론 환경 개선\n    3. S3 + Sagemaker + DB\n    4. Inference를 반복적으로 수행하지 않게 개선\n    5. 통일되지 않은 데이터 타입, 변수명 등 전수조사 및 통일\n    6. 이러한 작업을 통한 데이터 가시성 확보\n\n\n사실 데이터쪽 업무를 하시는 분들이라면 아시겠지만, 당연히 필요한 일을 여러가지 이유로 하지 못하는 경우가 많습니다. 위의 사례를 통해 문제점 발견부터 의사결정권자와 동료들을 설득하는 과정, 개선하는 작업, 이후 시각화를 통한 추가 개선 사항 도출까지 많은 부분을 배운 것 같습니다.\n\n\n### 네트워킹\n\n네트워킹 같은 경우 사람이 50명 가량 되어 여러 팀으로 나누어 진행하였습니다. 팀마다 발표하신 연사분들이 10분씩 돌아가며 질답을 받아주시고, 중간중간 자유롭게 주변 사람들하고 네트워킹 하는 시간을 가졌는데, 서먹할 것이라는 예상과 다르게 다들 엄청 적극적으로 네트워킹을 하셨던 것 같습니다. (순간 여기가 한국이 맞나 생각이 들었습니다 ^^;) 덕분에 소심한 저도 조금씩 질문도 하고 명함도 주고받고 했던 것 같네요.\n\n아래는 제가 주로 질문했던 질문입니다.\n\n1. (Grab님에게) Socar에서 airflow dev 환경 구성할 때 Dev용 DW는 어떻게 구성하는지?\n    - (답변) Dev용 DW가 따로 있고 Test를 하는 사람이 데이터를 그때마다 임의로 구성하여 테스트\n    - 제가 궁금했던건 데이터가 다른 데이터를 복잡하게 의존하는 경우가 많아서 그런 경우 기존 DW와 비슷하게 구성해야 하는 경우가 있고 결국 효율성을 위해 운영환경과 비슷하게 구성해야 하는 경우가 많은데, 어떻게 하고있는지 궁금해서 여쭤봤습니다. 역시 운영환경과 비슷하게 하는건 리소스의 문제가 있기 때문에 작업자가 약간 힘들더라도 개별로 데이터를 구성하여 테스트를 한다고 하네요.\n\n2. (Grab님에게) BigQuery의 장점?\n    - (답변) 대충 넣어도 사용하기 편하고, 성능이 좋다. 비용은 모르겠다.\n    - 대충 넣어도 사용하기 편한건 제가 직접 경험해보지 않아 모르겠지만 성능은 AWS Redshift Serverless와 별 차이 없는게 벤치마크로 확인되어 인식의 차이가 아닌가 싶습니다. 비용도 AWS 대비 BigQuery가 비싼 케이스가 많은 것 같은데 사용 편의성에 묻혀서 많은 고객들이 그냥 사용하는 것 같기도 하네요.\n\n3. (이은지님에게) 공공데이터용 중간 Layer를 오픈소스로 공개하실 생각은 없는지?\n    - (답변) 회사 정책에 따라 확인해보겠다.\n    - 회사 자산이니 당연히 안될거라 생각하긴 했습니다..ㅎㅎ\n\n\n여러 스타트업, 중견기업, 대기업에 다니시는분들이 골고루 계셨던 것 같고 취업준비생 분들도 간혹 계셨던 것 같습니다. 평소에 자주 쓰던 앱을 개발한 회사에서 오신분들을 보니 신기하기도 하고 짧지만 궁금했던 것들을 물어보며 그들의 생각도 조금이나마 들어볼 수 있던 좋은 시간이었습니다.\n\n네트워킹을 1시간이나 잡아서 너무 많은 시간을 잡은 것 아닌가라는 생각을 했었는데, 마지막에는 다들 시간이 모자라서 허겁지겁 명함만 교환하고 아쉽게 헤어졌던 것 같네요.\n\n> [Programmers Youtube](https://www.youtube.com/playlist?list=PLz4XWo74AOaeXlr6zxjA_24vr8qoSzxHE) 해당 세션 녹화 영상들이 업데이트 되었습니다.\n"},{"excerpt":"2022 Socar Data Meet-Up 어느날, 링크드인 피드를 둘러보던 중 관심이 가는 글을 보았습니다. 바로 2022 쏘카 데이터 밋업인데요, 이전에 데이터 엔지니어링 컨퍼런스를 다녀온 후로 이런 오프라인 밋업에 대한 이미지가 좋아져서 바로 등록 신청 했습니다.  발표 주제는 아래와 같았습니다. 무려 2만대의 차량을 AI로 관리하는 방법 데이터로 …","fields":{"slug":"/socar-data-meetup/"},"frontmatter":{"date":"October 27, 2022","title":"2022 Socar Data Meetup","tags":["Socar","Data","Meetup"]},"rawMarkdownBody":"\n\n## 2022 Socar Data Meet-Up\n\n어느날, 링크드인 피드를 둘러보던 중 관심이 가는 [글](https://www.linkedin.com/feed/update/urn:li:activity:6986550988979539968/?updateEntityUrn=urn%3Ali%3Afs_feedUpdate%3A%28V2%2Curn%3Ali%3Aactivity%3A6986550988979539968%29)을 보았습니다. 바로 2022 쏘카 데이터 밋업인데요, 이전에 [데이터 엔지니어링 컨퍼런스](https://dev-owner.github.io/blog/review-programmers-data-engineering-conference)를 다녀온 후로 이런 오프라인 밋업에 대한 이미지가 좋아져서 바로 등록 신청 했습니다.\n\n![socar-meetup](./2022-10-27-1.png)\n\n발표 주제는 아래와 같았습니다.\n\n1. 무려 2만대의 차량을 AI로 관리하는 방법\n2. 데이터로 비즈니스 급속 성장 부스터 달기\n3. 데이터로 고객경험 개선하기\n4. 기술로 쏘카의 핵심 비즈니스 문제 해결하기\n\n![](./2022-10-27-2.png)\n\n조금 일찍 도착하여 먼저 도착하신분들과 쏘카에서 제공해준 간단한 저녁거리를 먹으며 담소를 나누었는데, 이번 밋업 경쟁률이 8:1이라는 소리를 듣고 꽤 놀랐습니다 :) 한편으로는 제가 너무도 운이 좋게 뽑혔구나 생각도 들었구요.\n\n사실, 신청 당시에 바빠서 주제를 대충 보고 넘어갔다가 당일에 도착해서 대부분 `Data Science`쪽 관련 내용이라는것을 깨달았습니다. (필자는 Data Engineering쪽에 관심이 더 많았습니다..) 어쨌든 데이터쪽 분야 주제는 모두 흥미롭기 때문에 크게 실망하지 않고 세션 4개를 모두 잘 들었습니다.\n\n![](./2022-10-27-3.png)\n\n세션들은 모두 재밌게 들었는데 포스팅 목적으로 간 것이 아니라 따로 기록을 하지 않아 세부적인 내용을 공유드릴 수가 없어서 아쉽습니다. 대략적인 느낌만 공유 드리자면 데이터 조직의 크기나 하고 있는 일들을 봤을 때, `이 회사 정말 데이터에 진심`이구나를 느꼈습니다. 비즈니스에서 풀어야 하는 문제들도 많은것 같고 그러한 문제들을 하나하나 데이터에 기반하여 잘 풀어나가는 것이 뭔가 이상적인 모습처럼 보였어요.\n\n![](./2022-10-27-4.png)\n\n놀랐던것 중에 하나는 연사분들은 모두 팀장분들이셨는데 그 중 한분이 4년전 인턴으로 시작해서 지금 팀장역할을 하고 있는 모습이 정말 성과 위주로 사람을 평가한다고 느꼈습니다. 놀람 포인트가 하나 더 있는데, AI관련되어 Lab처럼 각종 유명 저널이나 컨퍼런스에 꾸준히 논문도 등록하고 있는것으로 보여서 그저 돈버는데만 집중하기보다 구성원들의 커리어와 업계에 기여를 하고있다는 느낌도 많이 받았습니다.\n\n![](./2022-10-27-5.png)\n\n세션이 다 끝나고, 쏘카측에서 발표 팀원분들과 직접적으로 Q&A를 할 수 있는 방을 따로 잡아 시간을 마련해 주셨습니다. 개인적으로 다른분들과 네트워킹 시간이 따로 없어 아쉬운 부분이 있었지만 그래도 쏘카 구성원들과 만날 수 있어서 좋았습니다.\n\n저는 죄송스럽게도 발표해주신 팀들보다 Data Engineering팀에 관심이 많았는데 마침 해당 팀도 방에서 Q&A를 진행해 주셔서 운좋게 참석할 수 있었습니다.\n\n들어가보니 제가 평소에 흥미롭게 읽었던 [데이터에 신뢰성과 재사용성까지, Analytics Engineering with dbt](https://tech.socarcorp.kr/data/2022/07/25/analytics-engineering-with-dbt.html)글의 저자이신 험프리님이 해당 팀의 팀장 입장으로 계셔서 꽤나 놀랐습니다. 인사를 나누고, 제가 일하면서 궁금했던 점들을 몇가지 질문했는데 정말 시간이 금방 가더라구요. 다른분들 질문들도 재미있었고 정말 유익한 시간이었습니다.\n\n이렇게 팀원분들과 미팅까지 끝나니 어느덧 10시가 넘어 집으로 가는데 같은 방에서 Q&A를 하시던 분과 지하철역까지 걸어가면서 더 이야기를 할 정도로 다른 참석하신분들도 열정이 대단하셨던것 같습니다.\n\n평소 밖을 나가지 않는 성격이라 이런 오프라인 밋업을 선호하지 않았는데 2회차 밋업도 좋은 인상으로 남아 앞으로 점점 더 많이 기웃거릴것 같네요!"}]}},"pageContext":{}},"staticQueryHashes":[]}