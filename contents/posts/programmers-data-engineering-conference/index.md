---
title: "2022 실리콘밸리에서 날아온 데이터 엔지니어링 컨퍼런스"
description: "2022년 프로그래머스에서 주최한 실리콘밸리에서 날아온 데이터 엔지니어링 강의 컨퍼런스 후기"
date: 2022-11-10
update: 2022-11-10
tags:
- Data Engineering
- Programmers
---

# 실리콘밸리에서 날아온 데이터 엔지니어링 컨퍼런스

### 배경

제가 처음 [실리콘밸리에서 날아온 데이터 엔지니어링 코스](https://school.programmers.co.kr/learn/courses/14982)를 알게 된 건 아래 Youtube EO Channel에 올라온 한기용님 영상을 시청한 이후 입니다. 총 3부까지 있는 이 영상을 보고 나서 여러가지로 많은 생각을 하게 되었습니다. 혹시 아직 안보셨다면 한번쯤 가볍게 시청해보시는 것도 추천 드립니다.

![](./2022-11-10-1.png)


기존에 4년정도 데이터 엔지니어링 업무를 대기업에서 했었는데, 다른 곳에서는 어떻게 하고 있는지 궁금하기도 하고 내가 기존에 몰랐던 것들을 혹시 배울 수 있지 않을까 하여 코스를 신청하게 되었습니다. 듣고 보니 역시 기대를 저버리지 않고 강의가 나름 알차게 코스가 구성되어 있어 많은 걸 배울 수 있었던 것 같습니다. 역시 세상은 넓고 배울것은 많습니다 :)

이 코스는 2022년 10월 기준 벌써 10기를 운영할 만큼 관련 종사자분들이 많이 듣고 계시기도 한데 이번에 코스 수강생들 대상으로 기용님이 데이터 엔지니어링 [컨퍼런스를](https://school.programmers.co.kr/learn/courses/15230) 열어주셔서 다녀온 후기를 작성해보려 합니다.


![](./2022-11-10-2.png)
(출처 : https://www.linkedin.com/in/hannahhejang/)


### 목차

금일 컨퍼런스 목차입니다.

1. Airflow 환경 고도화하기 ([hoyeon lee](https://www.linkedin.com/in/ACoAAB0dV2QBZEoHPDMHVUaWR3F-okOKbAsuqhQ))
2. 공공데이터 적재하기 ([Eunji Yi](https://www.linkedin.com/in/ACoAADdQHFoBvXqcwhKQG5YBRI0MNzRqGv_9j7w))
3. 스타트업에서 데이터기반 의사결정 구조 만들기 ([Minjong Kim](https://www.linkedin.com/in/ACoAAAJgCuMBC6ob4tTNYE290unr86fVRLD7blM))
4. 참석자 네트워킹


비록 시간대가 퇴근 후 저녁시간대였지만 1번부터 3번까지 흥미로운 주제로 가득했고 이는 컨퍼런스에 참가할 충분한 동기부여가 되었습니다. 참석자간 네트워킹 시간 같은 경우, 제가 한번도 경험이 없기 때문에 사실 한국 특성상 서먹서먹하고 어색한 분위기가 흐르다가 끝나지 않을까 막연한 예상을 하고 일단 들어갔습니다.


![](./2022-11-10-3.png)
(출처 : https://www.linkedin.com/in/hannahhejang/)


### Airflow 환경 고도화하기

금일 컨퍼런스 첫번째 세션입니다. 쏘카의 [Grab](https://www.linkedin.com/in/ACoAAB0dV2QBZEoHPDMHVUaWR3F-okOKbAsuqhQ)님이 발표를 진행해 주셨습니다.

GKE에서 K8S에 Airflow를 운영중이셨고, 통합 저장소로 BigQuery를 사용중이셨습니다. Airflow는 외부 저장소에서 BigQuery로 데이터를 적재할때 Batch 작업을 하기 위해 주로 사용했네요.

Airflow 개발환경에 대한 이야기를 많이 말씀 해주셨습니다. 초기 아키텍처는 Git과 연계하여 DAG 버전관리와 동시에 Airflow에 배포되는 구조를 가져간 것 같구요. 운영환경 및 다른 동료들과 독립적인 환경을 구축하기 위해 Git Branch를 따로 가져가고 push되면 buddyworks, argocd를 통해 전용 airflow가 생성되어 테스트 및 검증 후 운영 merge되는 구조였다고 합니다.

이런 구조에서 발생했던 자원 낭비, 불편한 환경, 긴 피드백 루프등의 많은 이슈로 인해 개발 환경 파이프라인을 docker compose 기반 로컬 노트북 환경으로 개선을 했다고 합니다. GCP Service Account를 통합 인증 수단으로 활용하였고, DAG Parsing Optimization을 위해 .airflowignore를 적극적으로 활용하셨다고 해요.

이러한 개선 구조를 통해 클러스터를 띄우는 시간을 많이 단축시키고 피드백 루프를 단축시켜 생산성을 많이 향상시킬 수 있었다고 합니다.

이어서 테스트 환경에 대한 이야기가 나왔는데, DAG 기본 문법 등을 체크하기 위해 pytest를 활용하셨고, pre commit hook을 사용하셨다고 합니다. Github Action에서 컨벤션, 테스트, 검증 등을 추가로 진행했다고 하네요.

꿀팁들도 여러가지 소개해 주셨는데, 그 중에 CleanUp DAG를 만들어서 주기적으로 TI나 DagRun등의 정보를 삭제하여 전반적인 cluster 반응성 등을 향상시킨 점이 인상깊었습니다.

모니터링, DAG 운영 알람, 보안 및 RBAC 적용, 외부 접속 정보에 대한 secret 저장소 활용, gcp secret manager 적용 등 많은 내용을 얘기해 주셨지만 시간이 많지는 않은 관계로 깊이는 다루지 못했던것 같습니다.

이후 위 내용들을 포함한 전반적인 내용을 [SOCAR Tech Blog](https://tech.socarcorp.kr/data/2022/11/09/advanced-airflow-for-databiz.html)에서 소개해 주셔서 관심있으시면 한번 보시는걸 추천 드립니다.


### 공공데이터 적재하기

공공데이터 적재관련해서는 뱅크샐러드의 [Eunji Yi](https://www.linkedin.com/in/ACoAADdQHFoBvXqcwhKQG5YBRI0MNzRqGv_9j7w)님이 발표해주셨는데요, 처음 소개에서 NASA에서 일한 경력이 있으신게 아주 인상깊었습니다.

이후에 뱅크샐러드에서 공공데이터 수집 관련해서 고군분투기를 말씀해 주셨는데, 본격적으로 공공데이터를 사용하기 위해 고려해야 할 것들이 얼마나 많은지 알 수 있었습니다.

저는 이전에 한번 업무에서 공공데이터 수집을 해봤는데도 불구하고, 제대로 여러기관의 데이터를 사용하기 위해 필요한것들을 이번에 처음 알았는데요, 대표적으로 기억나는 어려운 점들은 아래와 같았습니다.


    1. 정의가 같은 컬럼이라도, 발행하는 기관이나 API에 따라 이름이 다를 수 있다.
    2. Enum으로 관리되어야 할 것 같은 상수값들이 역시 기관이나 API에 따라 이름이 다를 수 있다.
    3. API명세가 아닌 2번과 같은 값 같은 경우는 내용이 언제 바뀔지 모른다.
    4. 값이 기관에서만 알아볼 수 있는 특정 코드로 되어있는 경우가 대다수이다.
    5. 4번과 같은 코드는 해당 API를 제공하는 곳이 아니라 저 멀리 이상한 다른 기관 사이트의 깊숙히 숨겨진 어딘가에 있다.
    6. 공공기관에 문의는 한세월이다.


뱅크샐러드에서는 위의 1번~6번을 해결하기 위해 중간 Layer를 두어 잘 추상화하여 사용하고 계신다고 하였습니다.

사실 이런 부분이 실제 데이터를 본격적으로 사용하고자 할 때 크나큰 어려움을 겪는 부분이죠.
이런 데이터 표준과 같은 내용은 이미 제공하는 측에서 관리하여 이용자가 편하게 이용할 수 있게끔 관리해야 한다고 생각합니다. (많은 기관에서 데이터를 open하고 있는것은 아주 긍정적이지만, 아직 갈길이 먼 것 같습니다)



> 그닥 놀랍지 않게도 개인 개발자분이 중간 layer 비스무리한걸 [github](https://github.com/WooilJeong/PublicDataReader)에 올린걸 최근에 발견했습니다. 관심있으시면 한번 보시는걸 추천 드립니다. - 2022/11/21



### 스타트업에서 데이터기반 의사결정 구조 만들기

마지막 세션은 NOUL의 [Minjong Kim](https://www.linkedin.com/in/ACoAAAJgCuMBC6ob4tTNYE290unr86fVRLD7blM)님이 발표해주셨습니다.

스타트업에서 어떤 문제를 발견하고, 해당 문제를 그냥 지나치지 않고 데이터를 기반으로 의사결정하여 개선해나가는 과정을 말씀해 주셨습니다.
일을 하다 보니 데이터가 동료들이 작업하고 있는 환경의 데이터가 여기저기 파편화 되어 있고, 버전이 맞지 않으며 이로인해 비즈니스 임팩트까지 발생하는 것을 파악하셨고, 주 업무 분야가 아님에도 불구하고 이런것을 개선하기 위해 아래와 같은 과정을 진행하셨다고 합니다.


    1. NAS, Google Spreadsheet 기반 파일 사용 추적 후 DB에 정규화하여 데이터 사용 및 정합성 측면 개선
    2. ML 모델 평가 추론 환경 개선
    3. S3 + Sagemaker + DB
    4. Inference를 반복적으로 수행하지 않게 개선
    5. 통일되지 않은 데이터 타입, 변수명 등 전수조사 및 통일
    6. 이러한 작업을 통한 데이터 가시성 확보


사실 데이터쪽 업무를 하시는 분들이라면 아시겠지만, 당연히 필요한 일을 여러가지 이유로 하지 못하는 경우가 많습니다. 위의 사례를 통해 문제점 발견부터 의사결정권자와 동료들을 설득하는 과정, 개선하는 작업, 이후 시각화를 통한 추가 개선 사항 도출까지 많은 부분을 배운 것 같습니다.


### 네트워킹

네트워킹 같은 경우 사람이 50명 가량 되어 여러 팀으로 나누어 진행하였습니다. 팀마다 발표하신 연사분들이 10분씩 돌아가며 질답을 받아주시고, 중간중간 자유롭게 주변 사람들하고 네트워킹 하는 시간을 가졌는데, 서먹할 것이라는 예상과 다르게 다들 엄청 적극적으로 네트워킹을 하셨던 것 같습니다. (순간 여기가 한국이 맞나 생각이 들었습니다 ^^;) 덕분에 소심한 저도 조금씩 질문도 하고 명함도 주고받고 했던 것 같네요.

아래는 제가 주로 질문했던 질문입니다.

1. (Grab님에게) Socar에서 airflow dev 환경 구성할 때 Dev용 DW는 어떻게 구성하는지?
    - (답변) Dev용 DW가 따로 있고 Test를 하는 사람이 데이터를 그때마다 임의로 구성하여 테스트
    - 제가 궁금했던건 데이터가 다른 데이터를 복잡하게 의존하는 경우가 많아서 그런 경우 기존 DW와 비슷하게 구성해야 하는 경우가 있고 결국 효율성을 위해 운영환경과 비슷하게 구성해야 하는 경우가 많은데, 어떻게 하고있는지 궁금해서 여쭤봤습니다. 역시 운영환경과 비슷하게 하는건 리소스의 문제가 있기 때문에 작업자가 약간 힘들더라도 개별로 데이터를 구성하여 테스트를 한다고 하네요.

2. (Grab님에게) BigQuery의 장점?
    - (답변) 대충 넣어도 사용하기 편하고, 성능이 좋다. 비용은 모르겠다.
    - 대충 넣어도 사용하기 편한건 제가 직접 경험해보지 않아 모르겠지만 성능은 AWS Redshift Serverless와 별 차이 없는게 벤치마크로 확인되어 인식의 차이가 아닌가 싶습니다. 비용도 AWS 대비 BigQuery가 비싼 케이스가 많은 것 같은데 사용 편의성에 묻혀서 많은 고객들이 그냥 사용하는 것 같기도 하네요.

3. (이은지님에게) 공공데이터용 중간 Layer를 오픈소스로 공개하실 생각은 없는지?
    - (답변) 회사 정책에 따라 확인해보겠다.
    - 회사 자산이니 당연히 안될거라 생각하긴 했습니다..ㅎㅎ


여러 스타트업, 중견기업, 대기업에 다니시는분들이 골고루 계셨던 것 같고 취업준비생 분들도 간혹 계셨던 것 같습니다. 평소에 자주 쓰던 앱을 개발한 회사에서 오신분들을 보니 신기하기도 하고 짧지만 궁금했던 것들을 물어보며 그들의 생각도 조금이나마 들어볼 수 있던 좋은 시간이었습니다.

네트워킹을 1시간이나 잡아서 너무 많은 시간을 잡은 것 아닌가라는 생각을 했었는데, 마지막에는 다들 시간이 모자라서 허겁지겁 명함만 교환하고 아쉽게 헤어졌던 것 같네요.

> [Programmers Youtube](https://www.youtube.com/playlist?list=PLz4XWo74AOaeXlr6zxjA_24vr8qoSzxHE) 해당 세션 녹화 영상들이 업데이트 되었습니다.
